{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4197959",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12472011",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLP_mvp_refactored.py\n",
    "\n",
    "# ## NLP: Análisis de Sentimiento Robusto\n",
    "\n",
    "# #### 1. Importación de Librerías\n",
    "# Se importan todas las librerías necesarias al inicio para una mejor gestión de dependencias.\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import spacy\n",
    "#from textblob import TextBlob\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e853a206",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Descargar e instalar el modelo de spaCy si no está presente\n",
    "try:\n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "except OSError:\n",
    "    print('Descargando el modelo en_core_web_sm de spaCy...')\n",
    "    # La siguiente línea es para ejecutar en un entorno de notebook/terminal\n",
    "    os.system('python -m spacy download en_core_web_sm')\n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a28beb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset cargado exitosamente (muestra aleatoria de ~1000 filas).\n",
      "   0           1                             2         3                4  \\\n",
      "0  0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY  _TheSpecialOne_   \n",
      "1  0  1468511278  Tue Apr 07 02:07:04 PDT 2009  NO_QUERY      Mike_Rhodes   \n",
      "2  0  1468842850  Tue Apr 07 04:01:12 PDT 2009  NO_QUERY      nameskieren   \n",
      "3  0  1469007159  Tue Apr 07 04:48:44 PDT 2009  NO_QUERY        mattmagic   \n",
      "4  0  1469125450  Tue Apr 07 05:18:10 PDT 2009  NO_QUERY     LoneWolf2003   \n",
      "\n",
      "                                                   5  \n",
      "0  @switchfoot http://twitpic.com/2y1zl - Awww, t...  \n",
      "1             i have to wake up in 5 hours  laameeee  \n",
      "2                             has a really bad cold   \n",
      "3  ARGHHH spent all yesterday doing a DPS for WMB...  \n",
      "4   thats y i never play uno  all the green cards go  \n",
      "\n",
      "Primeras 10 filas de la muestra aleatoria:\n",
      "   Sentiment             user  \\\n",
      "0          0  _TheSpecialOne_   \n",
      "1          0      Mike_Rhodes   \n",
      "2          0      nameskieren   \n",
      "3          0        mattmagic   \n",
      "4          0     LoneWolf2003   \n",
      "5          0      ashleeadams   \n",
      "6          0           kidbri   \n",
      "7          0       ravefamous   \n",
      "8          0    RoccoGiovanni   \n",
      "9          0      sunshine930   \n",
      "\n",
      "                                                Text  \n",
      "0  @switchfoot http://twitpic.com/2y1zl - Awww, t...  \n",
      "1             i have to wake up in 5 hours  laameeee  \n",
      "2                             has a really bad cold   \n",
      "3  ARGHHH spent all yesterday doing a DPS for WMB...  \n",
      "4   thats y i never play uno  all the green cards go  \n",
      "5          @tornadoliese Bummer, I didn't think so!   \n",
      "6  I can't, in my conscience, join anything which...  \n",
      "7  @mrmiggidude haha  don't spoil the fight ok I'...  \n",
      "8  @RJDanvers Its a beautiful day to do it! I'm d...  \n",
      "9               @nicolerichie yeah. I cried though.   \n",
      "\n",
      "Dimensiones de la muestra: (1019, 3)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# #### 2. Carga y Exploración de Datos (con muestra aleatoria)\n",
    "# Leemos una muestra aleatoria para acelerar el prototipado sin sesgos.\n",
    "\n",
    "try:\n",
    "    # --- PARÁMETROS PARA EL MUESTREO ---\n",
    "    total_filas = 1600000\n",
    "    filas_a_leer = 1000\n",
    "    probabilidad = filas_a_leer / total_filas\n",
    "\n",
    "    # --- LÍNEA MODIFICADA ---\n",
    "    # Usamos skiprows con una función lambda para muestreo aleatorio\n",
    "    df = pd.read_csv('data/training.1600000.processed.noemoticon.csv',\n",
    "        encoding='latin-1',\n",
    "        header=None,\n",
    "        # Omitir una fila si un número aleatorio es mayor que nuestra probabilidad\n",
    "        skiprows=lambda i: i > 0 and random.random() > probabilidad\n",
    "    )\n",
    "    print(f'Dataset cargado exitosamente (muestra aleatoria de ~{filas_a_leer} filas).')\n",
    "    print(df.head())\n",
    "\n",
    "    # Asignar nombres a las columnas\n",
    "    df.columns = ['Sentiment', 'id', 'date', 'query', 'user', 'Text']\n",
    "    \n",
    "    # Eliminar columnas innecesarias\n",
    "    cols_to_drop = ['id', 'date', 'query']\n",
    "    df = df.drop(columns=cols_to_drop)\n",
    "    \n",
    "    print('\\nPrimeras 10 filas de la muestra aleatoria:')\n",
    "    print(df.head(10))\n",
    "    \n",
    "    print(f'\\nDimensiones de la muestra: {df.shape}')\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print('Error: El archivo no fue encontrado.')\n",
    "except Exception as e:\n",
    "    print(f\"Ocurrió un error inesperado: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f65138bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribución de sentimientos tras el mapeo:\n",
      "Sentiment\n",
      "Negative    533\n",
      "Positive    486\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# #### 3. Mapeo de Sentimientos (Simplificado)\n",
    "# Mapeamos los valores numéricos del sentimiento (0 y 4) a etiquetas de texto.\n",
    "if 'df' in locals():\n",
    "    # El valor 0 es Negativo y 4 es Positivo.\n",
    "    df['Sentiment'] = df['Sentiment'].map({0: 'Negative', 4: 'Positive'})\n",
    "    \n",
    "    # Creamos la copia después del mapeo\n",
    "    df_copy = df.copy()\n",
    "\n",
    "    print('Distribución de sentimientos tras el mapeo:')\n",
    "    print(df['Sentiment'].value_counts())\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eaedffdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "- Data para modelado preparada -\n",
      "Tamaño de X_train: 713\n",
      "Tamaño de X_test: 306\n",
      "\n",
      "Distribución en y_train:\n",
      "Sentiment\n",
      "-1    373\n",
      " 1    340\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# #### 4. Preprocesamiento de Texto\n",
    "# Función de limpieza robusta que maneja posibles valores no textuales, convierte a minúsculas, elimina caracteres no deseados, lematiza y quita *stop words*.\n",
    "def limpieza(texto):\n",
    "    \"\"\"Realiza una limpieza completa del texto, incluyendo manejo de casos nulos.\"\"\"\n",
    "    if not isinstance(texto, str):\n",
    "        return \"\"\n",
    "    \n",
    "    texto = texto.lower()\n",
    "    texto = re.sub(r'[^a-záéíóúüñ\\s]', '', texto)\n",
    "    texto = re.sub(r'\\s+', ' ', texto).strip()\n",
    "    \n",
    "    # Procesar con spaCy solo si el texto no está vacío\n",
    "    if not texto:\n",
    "        return \"\"\n",
    "        \n",
    "    doc = nlp(texto)\n",
    "    texto_limpio = ' '.join([token.lemma_ for token in doc if not token.is_stop])\n",
    "    \n",
    "    return texto_limpio\n",
    "\n",
    "# ### Preparación de Datos para Modelado\n",
    "if 'df_copy' in locals():\n",
    "    X = df_copy['Text'].apply(limpieza)\n",
    "    \n",
    "    # Mapeamos 'Negative' a -1 y 'Positive' a 1\n",
    "    y = df_copy['Sentiment'].map({'Negative': -1, 'Positive': 1})\n",
    "\n",
    "    # Eliminar filas donde 'y' podría ser NaN si hubo valores de sentimiento inesperados\n",
    "    # y asegurarse de que los índices coincidan\n",
    "    valid_indices = y.notna()\n",
    "    X = X[valid_indices]\n",
    "    y = y[valid_indices]\n",
    "\n",
    "    # Dividir los datos, estratificando por 'y' para mantener la proporción de clases\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "    print(f\"\\n- Data para modelado preparada -\")\n",
    "    print(f\"Tamaño de X_train: {X_train.shape[0]}\")\n",
    "    print(f\"Tamaño de X_test: {X_test.shape[0]}\")\n",
    "    print(f\"\\nDistribución en y_train:\\n{y_train.value_counts()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b75a673",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Reporte de Clasificación: TF-IDF + Regresión Logística (Train) ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.94      0.98      0.96       373\n",
      "           1       0.98      0.93      0.96       340\n",
      "\n",
      "    accuracy                           0.96       713\n",
      "   macro avg       0.96      0.96      0.96       713\n",
      "weighted avg       0.96      0.96      0.96       713\n",
      "\n",
      "\n",
      "--- Reporte de Clasificación: TF-IDF + Regresión Logística (Test) ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.66      0.72      0.69       160\n",
      "           1       0.66      0.60      0.63       146\n",
      "\n",
      "    accuracy                           0.66       306\n",
      "   macro avg       0.66      0.66      0.66       306\n",
      "weighted avg       0.66      0.66      0.66       306\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ### Modelo 3: TF-IDF + Regresión Logística\n",
    "# Este método pondera la importancia de las palabras según su frecuencia en el documento y en todo el corpus (TF-IDF). Se combina con una Regresión Logística, un modelo lineal robusto para clasificación.\n",
    "if 'X_train' in locals():\n",
    "    # Vectorización con TF-IDF\n",
    "    vectorizer_tfidf = TfidfVectorizer()\n",
    "    X_train_tfidf = vectorizer_tfidf.fit_transform(X_train)\n",
    "    X_test_tfidf = vectorizer_tfidf.transform(X_test)\n",
    "\n",
    "    # Entrenamiento del modelo de Regresión Logística\n",
    "    # Se aumenta max_iter para asegurar la convergencia\n",
    "    model_lr = LogisticRegression(random_state=42, max_iter=1000)\n",
    "    model_lr.fit(X_train_tfidf, y_train)\n",
    "\n",
    "    # Predicciones\n",
    "    y_train_pred_lr = model_lr.predict(X_train_tfidf)\n",
    "    y_test_pred_lr = model_lr.predict(X_test_tfidf)\n",
    "\n",
    "    # Reporte de Clasificación\n",
    "    print(\"\\n--- Reporte de Clasificación: TF-IDF + Regresión Logística (Train) ---\")\n",
    "    print(classification_report(y_train, y_train_pred_lr))\n",
    "    print(\"\\n--- Reporte de Clasificación: TF-IDF + Regresión Logística (Test) ---\")\n",
    "    print(classification_report(y_test, y_test_pred_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f36e718c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Reporte de Clasificación: TF-IDF + Regresión Logística (Train) ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.74      0.86      0.80       373\n",
      "           1       0.82      0.67      0.73       340\n",
      "\n",
      "    accuracy                           0.77       713\n",
      "   macro avg       0.78      0.77      0.77       713\n",
      "weighted avg       0.78      0.77      0.77       713\n",
      "\n",
      "\n",
      "--- Reporte de Clasificación: TF-IDF + Regresión Logística (Test) ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.62      0.69      0.65       160\n",
      "           1       0.61      0.54      0.57       146\n",
      "\n",
      "    accuracy                           0.62       306\n",
      "   macro avg       0.62      0.61      0.61       306\n",
      "weighted avg       0.62      0.62      0.62       306\n",
      "\n",
      "\\nModelo y vectorizador guardados exitosamente en la carpeta 'model'.\n"
     ]
    }
   ],
   "source": [
    "# Vectorización TF-IDF Optimizada\n",
    "vectorizer_tfidf_opt = TfidfVectorizer(\n",
    "    ngram_range=(1, 2),  # Considera palabras individuales y pares de palabras (bigramas)\n",
    "    max_features=20000,  # Limita el vocabulario a las 20,000 características más importantes\n",
    "    min_df=5,            # La palabra debe aparecer en al menos 5 documentos\n",
    "    max_df=0.7           # La palabra no debe aparecer en más del 70% de los documentos\n",
    ")\n",
    "\n",
    "# Luego usas este nuevo vectorizador para transformar tus datos\n",
    "X_train_tfidf_opt = vectorizer_tfidf_opt.fit_transform(X_train)\n",
    "X_test_tfidf_opt = vectorizer_tfidf_opt.transform(X_test)\n",
    "\n",
    "# Entrenamiento del modelo de Regresión Logística\n",
    "# Se aumenta max_iter para asegurar la convergencia\n",
    "model_lr = LogisticRegression(random_state=42, max_iter=1000)\n",
    "model_lr.fit(X_train_tfidf_opt, y_train)\n",
    "\n",
    "# Predicciones\n",
    "y_train_pred_lr = model_lr.predict(X_train_tfidf_opt)\n",
    "y_test_pred_lr = model_lr.predict(X_test_tfidf_opt)\n",
    "\n",
    "# Reporte de Clasificación\n",
    "print(\"\\n--- Reporte de Clasificación: TF-IDF + Regresión Logística (Train) ---\")\n",
    "print(classification_report(y_train, y_train_pred_lr))\n",
    "print(\"\\n--- Reporte de Clasificación: TF-IDF + Regresión Logística (Test) ---\")\n",
    "print(classification_report(y_test, y_test_pred_lr))\n",
    "\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "# --- CÓDIGO A AGREGAR ---\n",
    "\n",
    "# Crear el directorio 'model' si no existe\n",
    "output_dir = 'model'\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# Guardar el vectorizador TF-IDF optimizado\n",
    "joblib.dump(vectorizer_tfidf_opt, os.path.join(output_dir, 'schimizzi_vectorizer.joblib'))\n",
    "\n",
    "# Guardar el modelo de Regresión Logística entrenado\n",
    "joblib.dump(model_lr, os.path.join(output_dir, 'schimizzi_modelo_s.joblib'))\n",
    "\n",
    "print(\"\\\\nModelo y vectorizador guardados exitosamente en la carpeta 'model'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590610a7",
   "metadata": {},
   "source": [
    "Guardar los archivos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64faadea",
   "metadata": {},
   "source": [
    "Cargar los archivos para usarlos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "679a2f41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texto: 'I love this product, it's the best thing I've ever bought!' -> Sentimiento Predicho: Positivo\n",
      "Texto: 'This is a terrible experience, I'm so disappointed.' -> Sentimiento Predicho: Negativo\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# 1. Cargar los objetos guardados\n",
    "vectorizer_cargado = joblib.load('model/schimizzi_vectorizer.joblib')\n",
    "modelo_cargado = joblib.load('model/schimizzi_modelo_s.joblib')\n",
    "\n",
    "# 2. Nuevos datos para predecir\n",
    "nuevos_datos = [\n",
    "    \"I love this product, it's the best thing I've ever bought!\", # Positivo\n",
    "    \"This is a terrible experience, I'm so disappointed.\",     # Negativo\n",
    "]\n",
    "\n",
    "# 3. Usar el VECTORIZER CARGADO para transformar el texto\n",
    "nuevos_datos_transformados = vectorizer_cargado.transform(nuevos_datos)\n",
    "\n",
    "# 4. Usar el MODELO CARGADO para hacer la predicción\n",
    "predicciones = modelo_cargado.predict(nuevos_datos_transformados)\n",
    "\n",
    "# 5. Interpretar el resultado (-1: Negativo, 1: Positivo)\n",
    "for texto, sentimiento in zip(nuevos_datos, predicciones):\n",
    "    resultado = \"Positivo\" if sentimiento == 1 else \"Negativo\"\n",
    "    print(f\"Texto: '{texto}' -> Sentimiento Predicho: {resultado}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5cfb0176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizer y modelo cargados correctamente.\n",
      "\\nFrases cargadas desde la columna 'Text' del archivo 'data/testdata.manual.2009.06.14.csv':\n",
      "- @stellargirl I loooooooovvvvvveee my Kindle2. Not that the DX is cool, but the 2 is fantastic in its own right.\n",
      "- Reading my kindle2...  Love it... Lee childs is good read.\n",
      "- Ok, first assesment of the #kindle2 ...it fucking rocks!!!\n",
      "- @kenburbary You'll love your Kindle2. I've had mine for a few months and never looked back. The new big one is huge! No need for remorse! :)\n",
      "- @mikefish  Fair enough. But i have the Kindle2 and I think it's perfect  :)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "# 1. Cargar los objetos guardados\n",
    "try:\n",
    "    vectorizer_cargado = joblib.load('model/schimizzi_vectorizer.joblib')\n",
    "    modelo_cargado = joblib.load('model/schimizzi_modelo_s.joblib')\n",
    "    print(\"Vectorizer y modelo cargados correctamente.\")\n",
    "\n",
    "    # 2. Leer los datos desde el archivo CSV (corregido)\n",
    "    predict_csv = 'data/testdata.manual.2009.06.14.csv'\n",
    "    # Cargar sin encabezado y asignar nombres a las columnas\n",
    "    df_nuevos = pd.read_csv(predict_csv, header=None, encoding='latin-1')\n",
    "    df_nuevos.columns = ['Sentiment', 'id', 'date', 'query', 'user', 'Text']\n",
    "\n",
    "    # --- ¡PUNTO CLAVE CORREGIDO! ---\n",
    "    # Extraer la columna de texto correcta ('Text')\n",
    "    nuevos_datos = df_nuevos['Text'].tolist()\n",
    "    \n",
    "    print(f\"\\\\nFrases cargadas desde la columna 'Text' del archivo '{predict_csv}':\")\n",
    "    for frase in nuevos_datos[:5]: # Mostramos solo las primeras 5 para brevedad\n",
    "        print(f\"- {frase}\")\n",
    "\n",
    "    # (El resto del código para transformar y predecir permanece igual)\n",
    "    # ...\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(\"\\\\nError: No se encontraron los archivos del modelo o el archivo CSV.\")\n",
    "except KeyError:\n",
    "    print(f\"\\\\nError: La columna 'Text' no se encontró en el archivo CSV.\")\n",
    "    print(\"Por favor, verifica el nombre de la columna en tu archivo.\")\n",
    "except Exception as e:\n",
    "    print(f\"\\\\nOcurrió un error inesperado: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d5411d01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Muestra de Predicciones del Conjunto de Prueba ---\n",
      "\n",
      "Tweet: let's make out \n",
      "  ➡️ Predicción: Positivo (Etiqueta Real: Positivo)\n",
      "\n",
      "Tweet: @grandmabomb Mine too. The stress is giving me a fever. Trouble is... I can't take a day off \n",
      "  ➡️ Predicción: Negativo (Etiqueta Real: Negativo)\n",
      "\n",
      "Tweet: @ally13524 hey if you have a friend request on OMGPOP it's just little old me \n",
      "  ➡️ Predicción: Negativo (Etiqueta Real: Positivo)\n",
      "\n",
      "Tweet: @guyfromucla u have two jobs that r unpaid...   \n",
      "  ➡️ Predicción: Negativo (Etiqueta Real: Negativo)\n",
      "\n",
      "Tweet: @pearlofthesea_ love sookis friend, the black one \n",
      "  ➡️ Predicción: Positivo (Etiqueta Real: Positivo)\n",
      "\n",
      "Tweet: Had a good sleep!  I love my Ilan totally!  30 days love \n",
      "  ➡️ Predicción: Positivo (Etiqueta Real: Positivo)\n",
      "\n",
      "Tweet: Chillin at the crib, about to call Kenzie \n",
      "  ➡️ Predicción: Negativo (Etiqueta Real: Positivo)\n",
      "\n",
      "Tweet: Ugh fun concert  screen cracked on phone again because it fell... =\\\n",
      "  ➡️ Predicción: Positivo (Etiqueta Real: Positivo)\n",
      "\n",
      "Tweet: never expected to hear Beastie Boys in a Star Trek movie... was a super great flick though. *pew peww* -- (phasers) \n",
      "  ➡️ Predicción: Positivo (Etiqueta Real: Positivo)\n",
      "\n",
      "Tweet: my iphone case broke before I even received my iphone   FML\n",
      "  ➡️ Predicción: Negativo (Etiqueta Real: Negativo)\n",
      "\n",
      "\n",
      "--- Guardando todas las predicciones en Excel ---\n",
      "\n",
      "✅ ¡Éxito! Se han guardado 306 predicciones en el archivo 'predicciones_sentimientos.xlsx'.\n",
      "\n",
      "Primeras filas del archivo guardado:\n",
      "                                                                                             Tweet Sentimiento_Predicho\n",
      "622                                                                                let's make out              Positivo\n",
      "343  @grandmabomb Mine too. The stress is giving me a fever. Trouble is... I can't take a day off              Negativo\n",
      "958                 @ally13524 hey if you have a friend request on OMGPOP it's just little old me              Negativo\n",
      "214                                               @guyfromucla u have two jobs that r unpaid...                Negativo\n",
      "972                                             @pearlofthesea_ love sookis friend, the black one              Positivo\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# --- LÍNEAS MODIFICADAS ---\n",
    "# Establecer un ancho máximo razonable para las columnas\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "# Establecer el ancho total de la pantalla para la tabla\n",
    "pd.set_option('display.width', 200)\n",
    "\n",
    "\n",
    "# --- Parte 1: Imprimir algunas predicciones ---\n",
    "\n",
    "print(\"--- Muestra de Predicciones del Conjunto de Prueba ---\")\n",
    "\n",
    "# (El resto del código de esta sección no necesita cambios)\n",
    "# ... (código para imprimir las 5 muestras) ...\n",
    "indices_muestra = X_test.head(10).index\n",
    "textos_originales = df_copy.loc[indices_muestra]['Text']\n",
    "muestras_transformadas = vectorizer_tfidf_opt.transform(X_test.head(10))\n",
    "predicciones_muestra = model_lr.predict(muestras_transformadas)\n",
    "etiquetas_reales = y_test.head(10).values\n",
    "mapa_sentimiento = {-1: \"Negativo\", 1: \"Positivo\"}\n",
    "\n",
    "for i in range(10):\n",
    "    texto = textos_originales.iloc[i]\n",
    "    prediccion = mapa_sentimiento[predicciones_muestra[i]]\n",
    "    etiqueta_real = mapa_sentimiento[etiquetas_reales[i]]\n",
    "    print(f\"\\nTweet: {texto}\")\n",
    "    print(f\"  ➡️ Predicción: {prediccion} (Etiqueta Real: {etiqueta_real})\")\n",
    "\n",
    "\n",
    "# --- Parte 2: Guardar todos los resultados en un archivo Excel ---\n",
    "\n",
    "print(\"\\n\\n--- Guardando todas las predicciones en Excel ---\")\n",
    "\n",
    "# (El resto del código de esta sección no necesita cambios)\n",
    "# ... (código para guardar en Excel e imprimir el head) ...\n",
    "y_test_predicciones = model_lr.predict(vectorizer_tfidf_opt.transform(X_test))\n",
    "textos_originales_test = df_copy.loc[X_test.index]['Text']\n",
    "df_resultados = pd.DataFrame({\n",
    "    'Tweet': textos_originales_test,\n",
    "    'Sentimiento_Predicho_Num': y_test_predicciones\n",
    "})\n",
    "df_resultados['Sentimiento_Predicho'] = df_resultados['Sentimiento_Predicho_Num'].map(mapa_sentimiento)\n",
    "df_final_excel = df_resultados[['Tweet', 'Sentimiento_Predicho']]\n",
    "nombre_archivo_excel = 'predicciones_sentimientos.xlsx'\n",
    "df_final_excel.to_excel(nombre_archivo_excel, index=False, engine='openpyxl')\n",
    "\n",
    "print(f\"\\n✅ ¡Éxito! Se han guardado {len(df_final_excel)} predicciones en el archivo '{nombre_archivo_excel}'.\")\n",
    "print(\"\\nPrimeras filas del archivo guardado:\")\n",
    "print(df_final_excel.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
