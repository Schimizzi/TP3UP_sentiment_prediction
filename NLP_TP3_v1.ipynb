{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4197959",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "12472011",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLP_mvp_refactored.py\n",
    "\n",
    "# ## NLP: Análisis de Sentimiento Robusto\n",
    "\n",
    "# #### 1. Importación de Librerías\n",
    "# Se importan todas las librerías necesarias al inicio para una mejor gestión de dependencias.\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import spacy\n",
    "#from textblob import TextBlob\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e853a206",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Descargar e instalar el modelo de spaCy si no está presente\n",
    "try:\n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "except OSError:\n",
    "    print('Descargando el modelo en_core_web_sm de spaCy...')\n",
    "    # La siguiente línea es para ejecutar en un entorno de notebook/terminal\n",
    "    os.system('python -m spacy download en_core_web_sm')\n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4a28beb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset cargado exitosamente (muestra aleatoria de ~20000 filas).\n",
      "   0           1                             2         3                4  \\\n",
      "0  0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY  _TheSpecialOne_   \n",
      "1  0  1467822687  Mon Apr 06 22:22:52 PDT 2009  NO_QUERY    xVivaLaJuicyx   \n",
      "2  0  1467837762  Mon Apr 06 22:26:48 PDT 2009  NO_QUERY          Dogbook   \n",
      "3  0  1467842607  Mon Apr 06 22:28:09 PDT 2009  NO_QUERY  VanessaSingline   \n",
      "4  0  1467844505  Mon Apr 06 22:28:38 PDT 2009  NO_QUERY       luimoral85   \n",
      "\n",
      "                                                   5  \n",
      "0  @switchfoot http://twitpic.com/2y1zl - Awww, t...  \n",
      "1  @BatManYNG I miss my ps3, it's out of commissi...  \n",
      "2  Emily will be glad when Mommy is done training...  \n",
      "3  @BridgetsBeaches Thank you for letting people ...  \n",
      "4              I don't understand... I really don't   \n",
      "\n",
      "Primeras 10 filas de la muestra aleatoria:\n",
      "   Sentiment             user  \\\n",
      "0          0  _TheSpecialOne_   \n",
      "1          0    xVivaLaJuicyx   \n",
      "2          0          Dogbook   \n",
      "3          0  VanessaSingline   \n",
      "4          0       luimoral85   \n",
      "5          0  omgseriouslywtf   \n",
      "6          0           admdrw   \n",
      "7          0       gregcronin   \n",
      "8          0      themangoman   \n",
      "9          0     Kevin_Lately   \n",
      "\n",
      "                                                Text  \n",
      "0  @switchfoot http://twitpic.com/2y1zl - Awww, t...  \n",
      "1  @BatManYNG I miss my ps3, it's out of commissi...  \n",
      "2  Emily will be glad when Mommy is done training...  \n",
      "3  @BridgetsBeaches Thank you for letting people ...  \n",
      "4              I don't understand... I really don't   \n",
      "5  @GuruMN but this is canada  canada is weird. w...  \n",
      "6  @charlietm I know right. I dunno what is going...  \n",
      "7  missed Brent at praise band.   No fun to not h...  \n",
      "8  spent 1 hour to reach to Axis bank only to fin...  \n",
      "9  @TheLeagueSF Not Fun &amp; Furious? The new ma...  \n",
      "\n",
      "Dimensiones de la muestra: (19766, 3)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# #### 2. Carga y Exploración de Datos (con muestra aleatoria)\n",
    "# Leemos una muestra aleatoria para acelerar el prototipado sin sesgos.\n",
    "\n",
    "try:\n",
    "    # --- PARÁMETROS PARA EL MUESTREO ---\n",
    "    total_filas = 1600000\n",
    "    filas_a_leer = 20000\n",
    "    probabilidad = filas_a_leer / total_filas\n",
    "\n",
    "    # --- LÍNEA MODIFICADA ---\n",
    "    # Usamos skiprows con una función lambda para muestreo aleatorio\n",
    "    df = pd.read_csv('data/training.1600000.processed.noemoticon.csv',\n",
    "        encoding='latin-1',\n",
    "        header=None,\n",
    "        # Omitir una fila si un número aleatorio es mayor que nuestra probabilidad\n",
    "        skiprows=lambda i: i > 0 and random.random() > probabilidad\n",
    "    )\n",
    "    print(f'Dataset cargado exitosamente (muestra aleatoria de ~{filas_a_leer} filas).')\n",
    "    print(df.head())\n",
    "\n",
    "    # Asignar nombres a las columnas\n",
    "    df.columns = ['Sentiment', 'id', 'date', 'query', 'user', 'Text']\n",
    "    \n",
    "    # Eliminar columnas innecesarias\n",
    "    cols_to_drop = ['id', 'date', 'query']\n",
    "    df = df.drop(columns=cols_to_drop)\n",
    "    \n",
    "    print('\\nPrimeras 10 filas de la muestra aleatoria:')\n",
    "    print(df.head(10))\n",
    "    \n",
    "    print(f'\\nDimensiones de la muestra: {df.shape}')\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print('Error: El archivo no fue encontrado.')\n",
    "except Exception as e:\n",
    "    print(f\"Ocurrió un error inesperado: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f65138bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribución de sentimientos tras el mapeo:\n",
      "Sentiment\n",
      "Positive    9917\n",
      "Negative    9849\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# #### 3. Mapeo de Sentimientos (Simplificado)\n",
    "# Mapeamos los valores numéricos del sentimiento (0 y 4) a etiquetas de texto.\n",
    "if 'df' in locals():\n",
    "    # El valor 0 es Negativo y 4 es Positivo.\n",
    "    df['Sentiment'] = df['Sentiment'].map({0: 'Negative', 4: 'Positive'})\n",
    "    \n",
    "    # Creamos la copia después del mapeo\n",
    "    df_copy = df.copy()\n",
    "\n",
    "    print('Distribución de sentimientos tras el mapeo:')\n",
    "    print(df['Sentiment'].value_counts())\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eaedffdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "- Data para modelado preparada -\n",
      "Tamaño de X_train: 13836\n",
      "Tamaño de X_test: 5930\n",
      "\n",
      "Distribución en y_train:\n",
      "Sentiment\n",
      " 1    6942\n",
      "-1    6894\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# #### 4. Preprocesamiento de Texto\n",
    "# Función de limpieza robusta que maneja posibles valores no textuales, convierte a minúsculas, elimina caracteres no deseados, lematiza y quita *stop words*.\n",
    "def limpieza(texto):\n",
    "    \"\"\"Realiza una limpieza completa del texto, incluyendo manejo de casos nulos.\"\"\"\n",
    "    if not isinstance(texto, str):\n",
    "        return \"\"\n",
    "    \n",
    "    texto = texto.lower()\n",
    "    texto = re.sub(r'[^a-záéíóúüñ\\s]', '', texto)\n",
    "    texto = re.sub(r'\\s+', ' ', texto).strip()\n",
    "    \n",
    "    # Procesar con spaCy solo si el texto no está vacío\n",
    "    if not texto:\n",
    "        return \"\"\n",
    "        \n",
    "    doc = nlp(texto)\n",
    "    texto_limpio = ' '.join([token.lemma_ for token in doc if not token.is_stop])\n",
    "    \n",
    "    return texto_limpio\n",
    "\n",
    "# ### Preparación de Datos para Modelado\n",
    "if 'df_copy' in locals():\n",
    "    X = df_copy['Text'].apply(limpieza)\n",
    "    \n",
    "    # Mapeamos 'Negative' a -1 y 'Positive' a 1\n",
    "    y = df_copy['Sentiment'].map({'Negative': -1, 'Positive': 1})\n",
    "\n",
    "    # Eliminar filas donde 'y' podría ser NaN si hubo valores de sentimiento inesperados\n",
    "    # y asegurarse de que los índices coincidan\n",
    "    valid_indices = y.notna()\n",
    "    X = X[valid_indices]\n",
    "    y = y[valid_indices]\n",
    "\n",
    "    # Dividir los datos, estratificando por 'y' para mantener la proporción de clases\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "    print(f\"\\n- Data para modelado preparada -\")\n",
    "    print(f\"Tamaño de X_train: {X_train.shape[0]}\")\n",
    "    print(f\"Tamaño de X_test: {X_test.shape[0]}\")\n",
    "    print(f\"\\nDistribución en y_train:\\n{y_train.value_counts()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9b75a673",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Reporte de Clasificación: TF-IDF + Regresión Logística (Train) ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.87      0.85      0.86      6894\n",
      "           1       0.85      0.87      0.86      6942\n",
      "\n",
      "    accuracy                           0.86     13836\n",
      "   macro avg       0.86      0.86      0.86     13836\n",
      "weighted avg       0.86      0.86      0.86     13836\n",
      "\n",
      "\n",
      "--- Reporte de Clasificación: TF-IDF + Regresión Logística (Test) ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.74      0.71      0.72      2955\n",
      "           1       0.72      0.75      0.73      2975\n",
      "\n",
      "    accuracy                           0.73      5930\n",
      "   macro avg       0.73      0.73      0.73      5930\n",
      "weighted avg       0.73      0.73      0.73      5930\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ### Modelo 3: TF-IDF + Regresión Logística\n",
    "# Este método pondera la importancia de las palabras según su frecuencia en el documento y en todo el corpus (TF-IDF). Se combina con una Regresión Logística, un modelo lineal robusto para clasificación.\n",
    "if 'X_train' in locals():\n",
    "    # Vectorización con TF-IDF\n",
    "    vectorizer_tfidf = TfidfVectorizer()\n",
    "    X_train_tfidf = vectorizer_tfidf.fit_transform(X_train)\n",
    "    X_test_tfidf = vectorizer_tfidf.transform(X_test)\n",
    "\n",
    "    # Entrenamiento del modelo de Regresión Logística\n",
    "    # Se aumenta max_iter para asegurar la convergencia\n",
    "    model_lr = LogisticRegression(random_state=42, max_iter=1000)\n",
    "    model_lr.fit(X_train_tfidf, y_train)\n",
    "\n",
    "    # Predicciones\n",
    "    y_train_pred_lr = model_lr.predict(X_train_tfidf)\n",
    "    y_test_pred_lr = model_lr.predict(X_test_tfidf)\n",
    "\n",
    "    # Reporte de Clasificación\n",
    "    print(\"\\n--- Reporte de Clasificación: TF-IDF + Regresión Logística (Train) ---\")\n",
    "    print(classification_report(y_train, y_train_pred_lr))\n",
    "    print(\"\\n--- Reporte de Clasificación: TF-IDF + Regresión Logística (Test) ---\")\n",
    "    print(classification_report(y_test, y_test_pred_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f36e718c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Reporte de Clasificación: TF-IDF + Regresión Logística (Train) ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.81      0.78      0.79      6894\n",
      "           1       0.79      0.82      0.80      6942\n",
      "\n",
      "    accuracy                           0.80     13836\n",
      "   macro avg       0.80      0.80      0.80     13836\n",
      "weighted avg       0.80      0.80      0.80     13836\n",
      "\n",
      "\n",
      "--- Reporte de Clasificación: TF-IDF + Regresión Logística (Test) ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.74      0.70      0.72      2955\n",
      "           1       0.72      0.75      0.74      2975\n",
      "\n",
      "    accuracy                           0.73      5930\n",
      "   macro avg       0.73      0.73      0.73      5930\n",
      "weighted avg       0.73      0.73      0.73      5930\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Vectorización TF-IDF Optimizada\n",
    "vectorizer_tfidf_opt = TfidfVectorizer(\n",
    "    ngram_range=(1, 2),  # Considera palabras individuales y pares de palabras (bigramas)\n",
    "    max_features=20000,  # Limita el vocabulario a las 20,000 características más importantes\n",
    "    min_df=5,            # La palabra debe aparecer en al menos 5 documentos\n",
    "    max_df=0.7           # La palabra no debe aparecer en más del 70% de los documentos\n",
    ")\n",
    "\n",
    "# Luego usas este nuevo vectorizador para transformar tus datos\n",
    "X_train_tfidf_opt = vectorizer_tfidf_opt.fit_transform(X_train)\n",
    "X_test_tfidf_opt = vectorizer_tfidf_opt.transform(X_test)\n",
    "\n",
    "# Entrenamiento del modelo de Regresión Logística\n",
    "# Se aumenta max_iter para asegurar la convergencia\n",
    "model_lr = LogisticRegression(random_state=42, max_iter=1000)\n",
    "model_lr.fit(X_train_tfidf_opt, y_train)\n",
    "\n",
    "# Predicciones\n",
    "y_train_pred_lr = model_lr.predict(X_train_tfidf_opt)\n",
    "y_test_pred_lr = model_lr.predict(X_test_tfidf_opt)\n",
    "\n",
    "# Reporte de Clasificación\n",
    "print(\"\\n--- Reporte de Clasificación: TF-IDF + Regresión Logística (Train) ---\")\n",
    "print(classification_report(y_train, y_train_pred_lr))\n",
    "print(\"\\n--- Reporte de Clasificación: TF-IDF + Regresión Logística (Test) ---\")\n",
    "print(classification_report(y_test, y_test_pred_lr))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590610a7",
   "metadata": {},
   "source": [
    "Guardar los archivos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64faadea",
   "metadata": {},
   "source": [
    "Cargar los archivos para usarlos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "679a2f41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texto: 'I love this product, it's the best thing I've ever bought!' -> Sentimiento Predicho: Positivo\n",
      "Texto: 'This is a terrible experience, I'm so disappointed.' -> Sentimiento Predicho: Negativo\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# 1. Cargar los objetos guardados\n",
    "vectorizer_cargado = joblib.load('model/schimizzi_vectorizer.joblib')\n",
    "modelo_cargado = joblib.load('model/schimizzi_modelo_s.joblib')\n",
    "\n",
    "# 2. Nuevos datos para predecir\n",
    "nuevos_datos = [\n",
    "    \"I love this product, it's the best thing I've ever bought!\", # Positivo\n",
    "    \"This is a terrible experience, I'm so disappointed.\",     # Negativo\n",
    "]\n",
    "\n",
    "# 3. Usar el VECTORIZER CARGADO para transformar el texto\n",
    "nuevos_datos_transformados = vectorizer_cargado.transform(nuevos_datos)\n",
    "\n",
    "# 4. Usar el MODELO CARGADO para hacer la predicción\n",
    "predicciones = modelo_cargado.predict(nuevos_datos_transformados)\n",
    "\n",
    "# 5. Interpretar el resultado (-1: Negativo, 1: Positivo)\n",
    "for texto, sentimiento in zip(nuevos_datos, predicciones):\n",
    "    resultado = \"Positivo\" if sentimiento == 1 else \"Negativo\"\n",
    "    print(f\"Texto: '{texto}' -> Sentimiento Predicho: {resultado}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
