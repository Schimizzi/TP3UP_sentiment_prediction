{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0c8c5a6",
   "metadata": {},
   "source": [
    "# Comparación de Modelos de Sentimiento\n",
    "\n",
    "Este notebook compara el rendimiento de un modelo de **Regresión Logística con TF-IDF** (entrenado localmente) contra un modelo de **Transformers pre-entrenado (RoBERTa)** de la librería Hugging Face, especializado en análisis de sentimiento en tweets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38bc731f",
   "metadata": {},
   "source": [
    "### Paso 1: Instalar Librerías Necesarias\n",
    "\n",
    "Si es la primera vez que ejecutas este código, asegúrate de instalar las librerías `transformers` y `torch`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113c1e45",
   "metadata": {},
   "source": [
    "!pip install transformers\n",
    "!pip install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac297b7",
   "metadata": {},
   "source": [
    "### Paso 2: Importar Módulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc0f70ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\basta\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "import re\n",
    "import spacy\n",
    "import os\n",
    "from transformers import pipeline\n",
    "\n",
    "# Opciones de visualización de Pandas\n",
    "pd.set_option('display.max_colwidth', 120)\n",
    "pd.set_option('display.width', 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f79e8f5e",
   "metadata": {},
   "source": [
    "### Paso 3: Definir Funciones de Ayuda\n",
    "\n",
    "Se define la función de limpieza de texto y una nueva función para encapsular la predicción con el modelo local."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52697a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import os\n",
    "\n",
    "# Cargar el modelo de spaCy\n",
    "try:\n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "except OSError:\n",
    "    print(\"Descargando modelo de spaCy...\")\n",
    "    os.system('python -m spacy download en_core_web_sm')\n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# (El resto de tu código que usa la variable 'nlp')\n",
    "\n",
    "def limpieza(texto):\n",
    "    \"\"\"Realiza una limpieza completa del texto para el modelo local.\"\"\"\n",
    "    if not isinstance(texto, str):\n",
    "        return \"\"\n",
    "    texto = texto.lower()\n",
    "    texto = re.sub(r'[^a-z\\s]', '', texto) # Simplificado para inglés\n",
    "    texto = re.sub(r'\\s+', ' ', texto).strip()\n",
    "    if not texto:\n",
    "        return \"\"\n",
    "    doc = nlp(texto)\n",
    "    return ' '.join([token.lemma_ for token in doc if not token.is_stop])\n",
    "\n",
    "def predecir_con_modelo_local(textos, vectorizer, modelo):\n",
    "    \"\"\"Encapsula todo el proceso de predicción del modelo local.\"\"\"\n",
    "    textos_limpios = [limpieza(t) for t in textos]\n",
    "    textos_transformados = vectorizer.transform(textos_limpios)\n",
    "    predicciones = modelo.predict(textos_transformados)\n",
    "    \n",
    "    mapa_local = {-1: \"Negativo\", 1: \"Positivo\"}\n",
    "    return [mapa_local.get(p, \"Desconocido\") for p in predicciones]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c83d06d",
   "metadata": {},
   "source": [
    "### Paso 4: Carga, Predicción y Comparación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2c278560",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:4: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:5: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:4: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:5: SyntaxWarning: invalid escape sequence '\\s'\n",
      "C:\\Users\\basta\\AppData\\Local\\Temp\\ipykernel_7516\\392659926.py:4: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  vectorizer_cargado = joblib.load('model_robust\\schimizzi_vectorizer_1.6kk.joblib')\n",
      "C:\\Users\\basta\\AppData\\Local\\Temp\\ipykernel_7516\\392659926.py:5: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  modelo_cargado = joblib.load('model_robust\\schimizzi_modelo_1.6kk.joblib')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando el modelo local y el vectorizer...\n",
      "¡Modelo local cargado!\n",
      "\n",
      "Cargando el modelo pre-entrenado de Hugging Face...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¡Modelo de Hugging Face cargado!\n",
      "\n",
      "Realizando predicciones con ambos modelos...\n",
      "\n",
      "--- TABLA COMPARATIVA DE PREDICCIONES ---\n",
      "                                                                                                                                  Texto Original Tu Modelo Hugging Face  Confianza HF\n",
      "0       Nike rocks. I'm super grateful for what I've done with them :) &amp; the European Division of NIKE is BEYOND! @whitSTYLES @muchasmuertes  Positivo     Positivo      0.991169\n",
      "1           @pambeeslyjenna Jenna, I went to see Night At The Museum 2 today and I was so surprised to see three cast members from The Office...  Positivo     Positivo      0.957178\n",
      "2                                                                                                     Malcolm Gladwell might be my new man crush  Positivo     Positivo      0.707346\n",
      "3                                                                                                  Will the Lakers kick the Nuggets ass tonight?  Positivo      Neutral      0.632009\n",
      "4          My dad was in NY for a day, we ate at MESA grill last night and met Bobby Flay. So much fun, except I completely lost my voice today.  Negativo     Positivo      0.944120\n",
      "5                                                                       @morind45 Because the twitter api is slow and most client's aren't good.  Negativo     Negativo      0.931754\n",
      "6                                                                          is upset about the whole GM thing. life as i know it is so screwed up  Negativo     Negativo      0.971655\n",
      "7                                   @shannyoday I will take you on a date to see night at the museum 2 whenever you want...it looks soooooo good  Positivo     Positivo      0.991285\n",
      "8                                            giving weka an app engine interface, using the bird strike data for the tests, the logo is a given.  Negativo      Neutral      0.861371\n",
      "9                                                                                     Reading my kindle2...  Love it... Lee childs is good read.  Positivo     Positivo      0.989151\n",
      "10                                                     Wow everyone at the Google I/O conference got free G2's with a month of unlimited service  Positivo     Positivo      0.979939\n",
      "11                                    House Correspondents dinner was last night whoopi, barbara &amp; sherri went, Obama got a standing ovation  Positivo     Positivo      0.576958\n",
      "12   @spinuzzi: Has been a bit crazy, with steep learning curve, but LyX is really good for long docs. For anything shorter, it would be insane.  Negativo     Positivo      0.798451\n",
      "13         myfoxdc Barrie Students Back from Trip to China: A Silver Spring high school's class trip to China has en.. http://tinyurl.com/nlhqba  Positivo      Neutral      0.886798\n",
      "14   US planning to resume the military tribunals at Guantanamo Bay... only this time those on trial will be AIG execs and Chrysler debt holders  Positivo      Neutral      0.753575\n",
      "15                                                                                                       Math review. Im going to fail the exam.  Negativo     Negativo      0.951641\n",
      "16                                                                    After using LaTeX a lot, any other typeset mathematics just looks hideous.  Positivo     Negativo      0.856012\n",
      "17  Monday already. Iran may implode. Kitchen is a disaster. @annagoss seems happy. @sebulous had a nice weekend and @goldpanda is great. whoop.  Positivo     Positivo      0.341357\n",
      "18   @defsounds WTF is the point of deleting tweets if they can still be found in summize and searches? Twitter, please fix that. Thanks and bye  Negativo     Negativo      0.657531\n",
      "19                                                              @the_real_usher LeBron is cool.  I like his personality...he has good character.  Positivo     Positivo      0.980286\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # --- Cargar Modelos ---\n",
    "    print(\"Cargando el modelo local y el vectorizer...\")\n",
    "    vectorizer_cargado = joblib.load('model_robust\\schimizzi_vectorizer_1.6kk.joblib')\n",
    "    modelo_cargado = joblib.load('model_robust\\schimizzi_modelo_1.6kk.joblib')\n",
    "    print(\"¡Modelo local cargado!\")\n",
    "\n",
    "    print(\"\\nCargando el modelo pre-entrenado de Hugging Face...\")\n",
    "    sentiment_pipeline_hf = pipeline(\"sentiment-analysis\", model=\"cardiffnlp/twitter-roberta-base-sentiment\")\n",
    "    print(\"¡Modelo de Hugging Face cargado!\")\n",
    "\n",
    "    # --- Cargar Datos para Comparación ---\n",
    "    ruta_archivo_nuevo = 'data/testdata.manual.2009.06.14.csv'\n",
    "    df_comparacion = pd.read_csv(ruta_archivo_nuevo, header=None, encoding='latin-1')\n",
    "    df_comparacion.columns = ['Sentiment_Real', 'id', 'date', 'query', 'user', 'Text']\n",
    "    \n",
    "    # Tomamos una muestra para no tardar demasiado\n",
    "    textos_a_comparar = df_comparacion['Text'].sample(20).tolist()\n",
    "    \n",
    "    # --- Realizar Predicciones ---\n",
    "    \n",
    "    print(\"\\nRealizando predicciones con ambos modelos...\")\n",
    "    \n",
    "    predicciones_local = predecir_con_modelo_local(textos_a_comparar, vectorizer_cargado, modelo_cargado)\n",
    "    resultados_hf = sentiment_pipeline_hf(textos_a_comparar)\n",
    "    \n",
    "    # --- Formatear Resultados y Mostrar Tabla ---\n",
    "\n",
    "    mapa_hf = {'LABEL_0': 'Negativo', 'LABEL_1': 'Neutral', 'LABEL_2': 'Positivo'}\n",
    "    predicciones_hf_texto = [mapa_hf.get(r['label'], \"Desconocido\") for r in resultados_hf]\n",
    "    confianza_hf = [r['score'] for r in resultados_hf]\n",
    "\n",
    "    df_resultados = pd.DataFrame({\n",
    "        'Texto Original': textos_a_comparar,\n",
    "        'Tu Modelo': predicciones_local,\n",
    "        'Hugging Face': predicciones_hf_texto,\n",
    "        'Confianza HF': confianza_hf\n",
    "    })\n",
    "\n",
    "    print(\"\\n--- TABLA COMPARATIVA DE PREDICCIONES ---\")\n",
    "    # Usamos to_string() para que se muestre todo el texto sin truncar\n",
    "    print(df_resultados.to_string())\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(\"\\nError: No se encontraron los archivos del modelo o el archivo de datos.\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nOcurrió un error inesperado: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f6e0294",
   "metadata": {},
   "source": [
    "### Paso 5: Análisis de Resultados\n",
    "\n",
    "Al observar la tabla comparativa, se pueden extraer las siguientes conclusiones:\n",
    "\n",
    "- **Matices y Contexto:** El modelo de Hugging Face (RoBERTa) es un Transformer, por lo que es mucho mejor para entender el contexto, el sarcasmo y los matices del lenguaje que un modelo TF-IDF. \n",
    "- **Manejo de la Neutralidad:** Tu modelo solo puede clasificar como \"Positivo\" o \"Negativo\". El modelo de Hugging Face tiene una clase \"Neutral\", lo que le da más flexibilidad y precisión en textos que no tienen una carga sentimental clara.\n",
    "- **Confianza del Modelo:** La columna `Confianza HF` indica qué tan seguro está el modelo de su predicción. En textos ambiguos, esta confianza suele ser más baja.\n",
    "- **Velocidad vs. Precisión:** Tu modelo local es casi instantáneo, mientras que el de Hugging Face tarda más en cargar y predecir. Este es el clásico compromiso en Machine Learning: los modelos más grandes y precisos suelen ser más lentos y costosos computacionalmente."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
